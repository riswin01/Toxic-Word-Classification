{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dff8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotly\n",
    "#!pip install cufflinks\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import LayerNormalization\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3dbfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4da554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "223544    :Jerome, I see you never got around to this…! ...\n",
       "223545    ==Lucky bastard== \\n http://wikimediafoundatio...\n",
       "223546    ==shame on you all!!!== \\n\\n You want to speak...\n",
       "223547    MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...\n",
       "223548    \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...\n",
       "Name: comment_text, Length: 223549, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('jigsaw-toxic-comment-train.csv')\n",
    "validation = pd.read_csv('validation.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "display(train.head())\n",
    "train['comment_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacb1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37b18ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223549, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3189da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    202165\n",
       "1     21384\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51760154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "223544    0\n",
       "223545    0\n",
       "223546    0\n",
       "223547    1\n",
       "223548    0\n",
       "Name: toxic, Length: 223549, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d06aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(predictions,target):\n",
    "    '''\n",
    "    This methods returns the AUC Score when given the Predictions\n",
    "    and Labels\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61392b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n",
    "                                                  stratify=train.toxic.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)\n",
    "#(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a346408b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 6, 1619, 266, 11, 73, 2, 37, 1, 1572, 2508, 76, 1350, 2, 1, 1572, 3, 82, 1, 23, 111, 24, 415, 1, 108, 6, 550, 11, 80, 6, 1619, 266, 11, 73, 2, 37, 584, 7, 79, 14, 2288, 54, 29, 408]\n",
      "[  0   0   0 ...  54  29 408]\n"
     ]
    }
   ],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 2400\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "print(xtrain_seq[0])\n",
    "\n",
    "#zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index\n",
    "print(xtrain_pad[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12fb9690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2400, 300)         90077400  \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 100)               40100     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,117,601\n",
      "Trainable params: 90,117,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     input_length=max_len))\n",
    "    model.add(SimpleRNN(100))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db9be40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2795/2795 [==============================] - 8163s 3s/step - loss: 0.2292 - accuracy: 0.9207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x166b22e58b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, ytrain, epochs=1, batch_size=64*strategy.num_replicas_in_sync) #Multiplying by Strategy to run on TPU's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04330040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc: 0.94%\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fd679e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model = []\n",
    "scores_model.append({'Model': 'SimpleRNN','AUC_Score': roc_auc(scores,yvalid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d63d7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[80,\n",
       "  6,\n",
       "  1619,\n",
       "  266,\n",
       "  11,\n",
       "  73,\n",
       "  2,\n",
       "  37,\n",
       "  1,\n",
       "  1572,\n",
       "  2508,\n",
       "  76,\n",
       "  1350,\n",
       "  2,\n",
       "  1,\n",
       "  1572,\n",
       "  3,\n",
       "  82,\n",
       "  1,\n",
       "  23,\n",
       "  111,\n",
       "  24,\n",
       "  415,\n",
       "  1,\n",
       "  108,\n",
       "  6,\n",
       "  550,\n",
       "  11,\n",
       "  80,\n",
       "  6,\n",
       "  1619,\n",
       "  266,\n",
       "  11,\n",
       "  73,\n",
       "  2,\n",
       "  37,\n",
       "  584,\n",
       "  7,\n",
       "  79,\n",
       "  14,\n",
       "  2288,\n",
       "  54,\n",
       "  29,\n",
       "  408]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_seq[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6df486e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196018it [02:10, 16814.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196017 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe vectors in a dictionary:\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('C:/Users/Riswin/Desktop/glove.840B.300d.txt','r',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray([float(val) for val in values[1:]])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db5c4ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300257/300257 [00:02<00:00, 126340.25it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47f96aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 2400, 300)         90077400  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                70200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,147,651\n",
      "Trainable params: 70,251\n",
      "Non-trainable params: 90,077,400\n",
      "_________________________________________________________________\n",
      "CPU times: user 378 ms, sys: 557 ms, total: 936 ms\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    \n",
    "    # A simple LSTM with glove embeddings and one dense layer\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "\n",
    "    model.add(LSTM(50, dropout=0.3, recurrent_dropout=0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec1021de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[64,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_2/lstm_1/while/lstm_cell_1/dropout_2/random_uniform/RandomUniform\n (defined at /home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py:5251)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_28423]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_2/lstm_1/while/lstm_cell_1/dropout_2/random_uniform/RandomUniform:\nIn[0] sequential_2/lstm_1/while/lstm_cell_1/dropout_2/Shape:\n\nOperation defined at: (most recent call last)\n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n>>>     yield self.process_one()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 250, in wrapper\n>>>     runner = Runner(ctx_run, result, future, yielded)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 741, in __init__\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-44-0aee8a7b73b1>\", line 1, in <module>\n>>>     model.fit(xtrain_pad, ytrain, epochs=1, batch_size=64)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 679, in __call__\n>>>     return super(RNN, self).__call__(inputs, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2826, in call\n>>>     return super(LSTM, self).call(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 816, in call\n>>>     last_output, outputs, states = backend.rnn(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 4654, in rnn\n>>>     final_outputs = tf.compat.v1.while_loop(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 4640, in _step\n>>>     output, new_states = step_function(current_input,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 812, in step\n>>>     output, new_states = cell_call_fn(inputs, states, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2449, in call\n>>>     dp_mask = self.get_dropout_mask_for_cell(inputs, training, count=4)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 1215, in get_dropout_mask_for_cell\n>>>     return self._dropout_mask_cache.setdefault(kwargs=init_kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 6772, in setdefault\n>>>     default = self.default_factory(**kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 1183, in _create_dropout_mask\n>>>     return _generate_dropout_mask(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2953, in _generate_dropout_mask\n>>>     return [\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2954, in <listcomp>\n>>>     backend.in_train_phase(dropped_inputs, ones, training=training)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 4782, in in_train_phase\n>>>     return x()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2950, in dropped_inputs\n>>>     return backend.dropout(ones, rate)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 5251, in dropout\n>>>     return tf.nn.dropout(x, rate=level, noise_shape=noise_shape, seed=seed)\n>>> \n\nFunction call stack:\ntrain_function -> sequential_2_lstm_1_while_body_26358_rewritten\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-0aee8a7b73b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_2/lstm_1/while/lstm_cell_1/dropout_2/random_uniform/RandomUniform\n (defined at /home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py:5251)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_28423]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential_2/lstm_1/while/lstm_cell_1/dropout_2/random_uniform/RandomUniform:\nIn[0] sequential_2/lstm_1/while/lstm_cell_1/dropout_2/Shape:\n\nOperation defined at: (most recent call last)\n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n>>>     yield self.process_one()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 250, in wrapper\n>>>     runner = Runner(ctx_run, result, future, yielded)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 741, in __init__\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-44-0aee8a7b73b1>\", line 1, in <module>\n>>>     model.fit(xtrain_pad, ytrain, epochs=1, batch_size=64)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 679, in __call__\n>>>     return super(RNN, self).__call__(inputs, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2826, in call\n>>>     return super(LSTM, self).call(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 816, in call\n>>>     last_output, outputs, states = backend.rnn(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 4654, in rnn\n>>>     final_outputs = tf.compat.v1.while_loop(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 4640, in _step\n>>>     output, new_states = step_function(current_input,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 812, in step\n>>>     output, new_states = cell_call_fn(inputs, states, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2449, in call\n>>>     dp_mask = self.get_dropout_mask_for_cell(inputs, training, count=4)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 1215, in get_dropout_mask_for_cell\n>>>     return self._dropout_mask_cache.setdefault(kwargs=init_kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 6772, in setdefault\n>>>     default = self.default_factory(**kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 1183, in _create_dropout_mask\n>>>     return _generate_dropout_mask(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2953, in _generate_dropout_mask\n>>>     return [\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2954, in <listcomp>\n>>>     backend.in_train_phase(dropped_inputs, ones, training=training)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 4782, in in_train_phase\n>>>     return x()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2950, in dropped_inputs\n>>>     return backend.dropout(ones, rate)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 5251, in dropout\n>>>     return tf.nn.dropout(x, rate=level, noise_shape=noise_shape, seed=seed)\n>>> \n\nFunction call stack:\ntrain_function -> sequential_2_lstm_1_while_body_26358_rewritten\n"
     ]
    }
   ],
   "source": [
    "model.fit(xtrain_pad, ytrain, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4b809a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 16.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/lib/python3.8/site-packages (from transformers) (1.20.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./anaconda3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: requests in ./anaconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 7.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./anaconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: click in ./anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in ./anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in ./anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.1.2 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n"
     ]
    }
   ],
   "source": [
    "#! pip install kaggle_datasets\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from kaggle_datasets import KaggleDatasets\n",
    "! pip install transformers\n",
    "import transformers\n",
    "\n",
    "from tokenizers import BertWordPieceTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c80e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATA\n",
    "\n",
    "train1 = pd.read_csv('jigsaw-toxic-comment-train.csv')\n",
    "valid = pd.read_csv('validation.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01b23390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n",
    "    \"\"\"\n",
    "    Encoder for encoding the text into sequence of integers for BERT Input\n",
    "    \"\"\"\n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    tokenizer.enable_padding(length=maxlen)\n",
    "    all_ids = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
    "        text_chunk = texts[i:i+chunk_size].tolist()\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "    return np.array(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "877a533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMP DATA FOR CONFIG\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "MAX_LEN = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e3082802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(vocabulary_size=119547, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=None, lowercase=False, wordpieces_prefix=##)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First load the real tokenizer\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "# Save the loaded tokenizer locally\n",
    "tokenizer.save_pretrained('.')\n",
    "# Reload it with the huggingface tokenizers library\n",
    "fast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=False)\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e671703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 874/874 [00:20<00:00, 42.44it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 95.80it/s]\n",
      "100%|██████████| 250/250 [00:03<00:00, 82.45it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train = fast_encode(train1.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
    "x_valid = fast_encode(valid.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
    "x_test = fast_encode(test.content.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n",
    "\n",
    "y_train = train1.toxic.values\n",
    "y_valid = valid.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81cfd4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_train, y_train))\n",
    "    .repeat()\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_valid, y_valid))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(x_test)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cf4f9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=512):\n",
    "    \"\"\"\n",
    "    function for training the BERT model\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(cls_token)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "58d868d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7916642afdb47ab8975851b7af67025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/869M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_layer_norm', 'vocab_projector', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_word_ids (InputLayer)  [(None, 192)]            0         \n",
      "                                                                 \n",
      " tf_distil_bert_model (TFDis  TFBaseModelOutput(last_h  134734080\n",
      " tilBertModel)               idden_state=(None, 192,             \n",
      "                             768),                               \n",
      "                              hidden_states=None, att            \n",
      "                             entions=None)                       \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 768)              0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,734,849\n",
      "Trainable params: 134,734,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 13.9 s, sys: 2.15 s, total: 16 s\n",
      "Wall time: 34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    transformer_layer = (\n",
    "        transformers.TFDistilBertModel\n",
    "        .from_pretrained('distilbert-base-multilingual-cased')\n",
    "    )\n",
    "    model = build_model(transformer_layer, max_len=MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d47b211",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": " failed to allocate memory\n\t [[node Adam/Adam/update/mul_1\n (defined at /home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:201)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_42911]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Adam/Adam/update/mul_1:\nIn[0] Adam/Adam/update/ReadVariableOp:\t\nIn[1] Adam/Identity_1 (defined at /home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:128)\n\nOperation defined at: (most recent call last)\n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-69-3126dede9bb1>\", line 2, in <module>\n>>>     train_history = model.fit(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 532, in minimize\n>>>     return self.apply_gradients(grads_and_vars, name=name)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 672, in apply_gradients\n>>>     return self._distributed_apply(strategy, grads_and_vars, name,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 721, in _distributed_apply\n>>>     update_op = distribution.extended.update(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 699, in apply_grad_to_update_var\n>>>     return self._resource_apply_sparse_duplicate_indices(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 1285, in _resource_apply_sparse_duplicate_indices\n>>>     return self._resource_apply_sparse(summed_grad, handle, unique_indices,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py\", line 201, in _resource_apply_sparse\n>>>     m_t = tf.compat.v1.assign(m, m * coefficients['beta_1_t'],\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-3126dede9bb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  failed to allocate memory\n\t [[node Adam/Adam/update/mul_1\n (defined at /home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:201)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_42911]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Adam/Adam/update/mul_1:\nIn[0] Adam/Adam/update/ReadVariableOp:\t\nIn[1] Adam/Identity_1 (defined at /home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:128)\n\nOperation defined at: (most recent call last)\n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n>>>     self.ctx_run(self.run)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n>>>     yielded = ctx_run(next, result)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-69-3126dede9bb1>\", line 2, in <module>\n>>>     train_history = model.fit(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 532, in minimize\n>>>     return self.apply_gradients(grads_and_vars, name=name)\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 672, in apply_gradients\n>>>     return self._distributed_apply(strategy, grads_and_vars, name,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 721, in _distributed_apply\n>>>     update_op = distribution.extended.update(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 699, in apply_grad_to_update_var\n>>>     return self._resource_apply_sparse_duplicate_indices(\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\", line 1285, in _resource_apply_sparse_duplicate_indices\n>>>     return self._resource_apply_sparse(summed_grad, handle, unique_indices,\n>>> \n>>>   File \"/home/sudipta/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py\", line 201, in _resource_apply_sparse\n>>>     m_t = tf.compat.v1.assign(m, m * coefficients['beta_1_t'],\n>>> "
     ]
    }
   ],
   "source": [
    "n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c7a34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model = []\n",
    "scores_model.append({'Model': 'SimpleRNN','AUC_Score': 0.83})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38be598",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model.append({'Model': 'LSTM','AUC_Score': 0.94})\n",
    "scores_model.append({'Model': 'GRU','AUC_Score': 0.96})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4276dd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_8fafe_row0_col1{\n",
       "            background-color:  #67000d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_8fafe_row1_col1{\n",
       "            background-color:  #ad1117;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_8fafe_row2_col1{\n",
       "            background-color:  #fff5f0;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_8fafe_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >AUC_Score</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_8fafe_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "                        <td id=\"T_8fafe_row0_col0\" class=\"data row0 col0\" >GRU</td>\n",
       "                        <td id=\"T_8fafe_row0_col1\" class=\"data row0 col1\" >0.960000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8fafe_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_8fafe_row1_col0\" class=\"data row1 col0\" >LSTM</td>\n",
       "                        <td id=\"T_8fafe_row1_col1\" class=\"data row1 col1\" >0.940000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8fafe_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "                        <td id=\"T_8fafe_row2_col0\" class=\"data row2 col0\" >SimpleRNN</td>\n",
       "                        <td id=\"T_8fafe_row2_col1\" class=\"data row2 col1\" >0.830000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c88fc1a9a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(scores_model).sort_values(by='AUC_Score',ascending=False)\n",
    "results.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77430442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Accuracy = [0.83,0.94, 0.96]\n",
    "Methods = ['Simple', 'LSTM', 'GRU']\n",
    "Accuracy_pos = np.arange(len(Methods))\n",
    "plt.bar(Accuracy_pos, Accuracy, width=0.4, color=\"orange\")\n",
    "plt.xticks(Accuracy_pos, Methods)\n",
    "plt.title('Comparing the AUC accuracy of each model')\n",
    "plt.xlabel(\" ---> MODELS\")\n",
    "plt.ylabel(\" ---> ACCURACY\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29097274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeU0lEQVR4nO3debwcdb3m8c+ThT0QJVEhIQQEgSiLEBN08AIqmKAQ8IqyXDQog6jxil4UrjIs6ow6916DSjQiIiIioLJEJoAyCMiSIQmrYY1ASAxogoCEPeQ7f/x+ByqdPn3qnJzqTlLP+/U6r9NV9auqb3dX9dO1dJUiAjMzq68BnS7AzMw6y0FgZlZzDgIzs5pzEJiZ1ZyDwMys5hwEZmY15yBYh0g6UtLv2jSv0ZJC0qB2zK8MSaMkLZM0sD/bWt9I+rSkv+bXefM2zfM6Sce0Y149yevHdiXa7SNpUTtq6o6DoAlJR0iakxfgxyRdKWmvTtfVk4j4RUTsX8W0JT0i6X0VTPfI/Dovk/S8pBWF7mW9mVZEPBoRm0TEK/3Z1npP0mDgO8D++XV+otM1WfccBA0kfRE4A/hfwBuBUcAPgEkdLKtHa9I3897I4bVJRGwCTAQWd3Xnfq/yt/dy1pBl4Y3ABsC8ThdiJUSE//IfsBmwDDi0RZv1SUGxOP+dAayfh+0DLAK+DPwNeAw4GDgAeAD4O/CVwrROA34NXAQ8A9wG7FoYfhLw5zzsHuCQwrDJwE3A1Dzdb+R+NxbaBHAc8CDwJDANUB42EPgvYCnwMDAltx/U5Dn/HFgBPJ9fny8Do3P7jwOP5ul8tTDOgEL9TwAXA6/v4fXfB1hU6D4X+CEwE3gWeB/wAeB24B/AQuC0Qvuumgbl7uuAr+fX6Rngd8Cw3rbNwz8GLMjP5X8AjwDv6+Z5dFtjHr4XcDPwVB4+OfffML8nC4CngRtzv5Vel9z21fnz2nJ0fp7nMcA44JY8j8eAM4H1CuO/Ffg9adn5K/AV4E3Ac8DmhXZ7AEuAwWXXBeAt+f0K0vJybTev056F1+FOYJ/CsKOBe/N78RDwqYZxJwF35Of7Z2BCmfex2fJG+fW123U/D/9SnsZi4BP5+W9XGPc/SevKX4HpwIbNlvuOfPZ1cuZr2h8wAVhOkw/DQpuvAbOANwDD84L89cIbuhw4BRgM/Pe8El0ADMkr3wvAtrn9acDLwIdz+xNIH8qD8/BDgS1JH6ofzSvXFnnY5DyvzwGDSB8Yk1k1CK4AhpK2bJYUVpjjSOEyEngdcA3dBEFu/wiFDz5e+yD9cZ73rsCLwE55+PH5dRqZV4IfAb/s4fVfaYUgBcHTwH/Lr8EGuc3OuXuXvFId3FBT8cP9z6QPpg1z97f60HYM6QNtL2A90gr9Mt0HQasaR5E+oA7P7/nmwG552LQ83xGkoH5Xfu1Wel0a3w9eW44OzvPckPQBvidp2RhN+lA9PrcfQvrA+rf8mg4BxudhM4FPF+YzFfh+H9aFlV7fJuOOIIXqAbnm/XL38Dz8A8CbAQF7kwJq9zxsHGm52C+POwLYsaf3sZv3qTfra6vnOyG/z28DNs7TKAbBGcAM4PV52r8Fvtlsue/IZ18nZ76m/QFHAo/30ObPwAGF7vcDjxTe0OeBgbl7SF4Yxhfaz+W1D4XTgFmFYQPyCvrubuZ9BzApP54MPNowfDKrBsFehe6LgZPy42spfMsifdvuSxCMLPS7FTgsP74XeG9h2BakD6tWIbvSCkEKgvN6eD/OAKY21FT8cD+50PYzwFV9aHsKhRADNgJeopsg6KHGfwcubdJmQF52du3pdWl8P/JydEMPNRzfNV9SCN3eTbuPAjflxwOBx4FxfVgXVnp9m4x7IvDzhn5XAx/vpv1lwOfz4x91vZ5N2nX7PnbzuvZmfW31fM+hEDikIApgO1KYPQu8uTD8ncDD3b2/7f7zMYKVPQEM62Ef65akTfcuC3K/V6cRrx2AfD7//2th+PNAcd/3wq4HEbGCtKm6JYCkj0m6Q9JTkp4ifdsY1mzcFh4vPH6uMO8tG8YvM63eTH9r4NJC7fcCr5D2HffGSnVJGi/pD5KWSHqatGUzrPmoLevrTduVXquIeI60rDTVQ41bkT5QGg0jfTtvNqyMxtfpLZKukPS4pH+Qjnn1VAPA5cAYSduSvnE/HRG3dtO2p3Whla2BQ7uWj7yM7EX6woCkiZJmSfp7HnZAyfqhd+95b9bXVs+3cX0qthtO+vIwt/Bcr8r91wgOgpXdQtoUPLhFm8WkhbjLqNyvr7bqeiBpAGlXymJJW5N2u0wh7bMdCvyJ9O2iS6zGfB/L81qljm70dl4LgYkRMbTwt0FE/KWX02mc7wWkTeytImIz0r5WrTJW/1rptZK0IWmXTnda1biQtMuj0VLSstds2LOkD5Ku+Q9k1Q+Rxtfph8B9wPYRsSnpGEBPNRARL5C2HI8EjiIdH+rO6qwLC0lbBMXlY+OI+Jak9YHfkHbBvTEv+zPL1F+xVs/3MVZeh0YVHi8lBcpbC891s2g4GaKTHAQFEfE0aTfANEkHS9pI0uD87eR/52a/BE6WNFzSsNz+/NWY7R6SPpS3Qo4n7WefRdrPGKR9lkg6mrRF0F8uBj4vaYSkoaRN9Vb+Cmzbi+lPB/5nDjTy6zWpT5WubAjw94h4QdI44Ih+mGZPfg0cKOldktYDTqd1+LSq8RfA+yR9RNIgSZtL2i1vDZ4DfEfSlpIGSnpn/lB8ANhA0gfyaZknk44dtDKEdCB1maQdgU8Xhl0BvEnS8ZLWlzRE0vjC8PNIuxkPovWyvTrrwvmk1/T9+blukM+nH0k6DrM+adlfLmkiUDwt+ifA0ZLeK2lAXoZ3LDnf1dHq+V4MTJY0RtJGwKldI+X39sfAVElvAMg1v78NNZfiIGgQEd8Bvkha2ZaQvn1MIe2jhHR2zhzgLuBu0pk+31iNWV5O2i/7JOkb2Ici4uWIuId0BsktpA/hnUlnQvSXH5POqLiLdIbLTNKBs+7Oq/8maSV4StIJJab/XdK34t9JeoYUbuNbj1LKZ4Cv5WmeQloBKxUR80gH5S8kffN7hnSWyYu9rTEiHiXt5vg30lkpd5AOtEM6WeBuYHYe9m1gQP6C8hngbOAvpC2Enn6AdAIpgJ4hvdcXFWp4hrTb50DSbpQHgX0Lw28inSV2W0Q80mIefV4XImIh6cyfr/Daeval/HyfAf6V9Lo9mZ/HjMK4t5LOKppKOmh8PSt/U69Kt883Iq4kHQu6Fpif/xedmPvPyrvqrgF2aEPNpXSdSmgdIOk00lkF/7IG1DIRmB4R7Vih1mqSNiGd8rh9RDzc4XIqIela4IKIOLvTtVj1vEVQU5I2lHRA3j0xgrQpe2mn61pTSTow7yrcmLTv+m7SmTvrHEnvAHansBVh6zYHQX2JtK/7SdKuoXtJuzGsuUm89kOi7Umnya5zm9OSfkbabXF83kVjNeBdQ2ZmNectAjOzmlsTLk7VK8OGDYvRo0d3ugwzs7XK3Llzl0ZE0x+xrXVBMHr0aObMmdPpMszM1iqSFnQ3zLuGzMxqzkFgZlZzDgIzs5pzEJiZ1ZyDwMys5hwEZmY15yAwM6s5B4GZWc05CMzMam6t+2WxWX/S6VXf5bLv4lRfELLd1uTlAapbJrxFYGZWcw4CM7OacxCYmdWcg8DMrOYcBGZmNVers4bqekaAmVkr3iIwM6s5B4GZWc05CMzMas5BYGZWcw4CM7OacxCYmdWcg8DMrOYcBGZmNecgMDOrOQeBmVnNOQjMzGrOQWBmVnMOAjOzmnMQmJnVnIPAzKzmHARmZjXnIDAzqzkHgZlZzTkIzMxqrtIgkDRB0v2S5ks6qcnwzST9VtKdkuZJOrrKeszMbFWVBYGkgcA0YCIwBjhc0piGZp8F7omIXYF9gP+StF5VNZmZ2aqq3CIYB8yPiIci4iXgQmBSQ5sAhkgSsAnwd2B5hTWZmVmDKoNgBLCw0L0o9ys6E9gJWAzcDXw+IlY0TkjSsZLmSJqzZMmSquo1M6ulKoNATfpFQ/f7gTuALYHdgDMlbbrKSBFnRcTYiBg7fPjw/q7TzKzWqgyCRcBWhe6RpG/+RUcDl0QyH3gY2LHCmszMrEGVQTAb2F7SNvkA8GHAjIY2jwLvBZD0RmAH4KEKazIzswaDqppwRCyXNAW4GhgInBMR8yQdl4dPB74OnCvpbtKupBMjYmlVNZmZ2aoqCwKAiJgJzGzoN73weDGwf5U1mJlZa/5lsZlZzTkIzMxqzkFgZlZzDgIzs5pzEJiZ1ZyDwMys5hwEZmY15yAwM6s5B4GZWc05CMzMas5BYGZWcw4CM7OacxCYmdVcj0Eg6W3tKMTMzDqjzBbBdEm3SvqMpKFVF2RmZu3VYxBExF7AkaTbTs6RdIGk/SqvzMzM2qLUMYKIeBA4GTgR2Bv4nqT7JH2oyuLMzKx6ZY4R7CJpKnAv8B7gwIjYKT+eWnF9ZmZWsTK3qjwT+DHwlYh4vqtnRCyWdHJllZmZWVuUCYIDgOcj4hUASQOADSLiuYj4eaXVmZlZ5cocI7gG2LDQvVHuZ2Zm64AyQbBBRCzr6siPN6quJDMza6cyQfCspN27OiTtATzfor2Zma1FyhwjOB74laTFuXsL4KOVVWRmZm3VYxBExGxJOwI7AALui4iXK6/MzMzaoswWAaQQGANsALxdEhFxXnVlmZlZu/QYBJJOBfYhBcFMYCJwI+AgMDNbB5Q5WPxh4L3A4xFxNLArsH6lVZmZWduUCYLnI2IFsFzSpsDfgG2rLcvMzNqlzDGCOfny0z8G5gLLgFurLMrMzNqnZRBIEvDNiHiKdF+Cq4BNI+KudhRnZmbVa7lrKCICuKzQ/YhDwMxs3VLmGMEsSe+ovBIzM+uIMscI9gU+JWkB8CzpR2UREbtUWpmZmbVFmSCYWHkVZmbWMWWCICqvwszMOqZMEPwfUhiIdImJbYD7gbf2NKKkCcB3gYHA2RHxrSZt9gHOAAYDSyNi73Klm5lZfyhz0bmdi935ktSf6mk8SQOBacB+wCJgtqQZEXFPoc1Q4AfAhIh4VNIbele+mZmtrjJnDa0kIm4DypxFNA6YHxEPRcRLwIXApIY2RwCXRMSjedp/6209Zma2espcdO6Lhc4BwO7AkhLTHgEsLHQvAsY3tHkLMFjSdcAQ4LvNrmoq6VjgWIBRo0aVmLWZmZVV5hjBkMLj5aRjBr8pMZ6a9Gs88DwI2IN0UbsNgVskzYqIB1YaKeIs4CyAsWPH+uC1mVk/KnOM4PQ+TnsRsFWheySwuEmbpRHxLOmWmDeQrm76AGZm1hY9HiOQ9Pt8ULer+3WSri4x7dnA9pK2kbQecBgwo6HN5cC7JQ2StBFp19G9pas3M7PVVmbX0PB80TkAIuLJMmf3RMRySVOAq0mnj54TEfMkHZeHT4+Ie/OF7O4CVpBOMf1TX56ImZn1TZkgeEXSqK4zeyRtTckfmUXETNJdzYr9pjd0/wfwH+XKNTOz/lYmCL4K3Cjp+tz9T+QzeMzMbO1X5mDxVflHZHuSzgT6QkQsrbwyMzNrizIHiw8BXo6IKyLit6RbVh5ceWVmZtYWZX5ZfGpEPN3VkQ8cn1pZRWZm1lZlgqBZmzLHFszMbC1QJgjmSPqOpDdL2lbSVNJN7M3MbB1QJgg+B7wEXAT8CngB+GyVRZmZWfuUOWvoWeAkePXS0hvnfmZmtg4oc9bQBZI2lbQxMA+4X9KXqi/NzMzaocyuoTER8Q/gYNKvhEcBR1VZlJmZtU+ZIBgsaTApCC6PiJerLcnMzNqpTBD8CHgE2Bi4IV9r6OmWY5iZ2VqjzMHi7wHfK/RaIOmw6koyM7N2Kn3PYkmbSfqEpGuAWyusyczM2qjlFoGkDYGDSDeZ351028qDgRsqr8zMzNqi2y0CSb8g3TJyf+BMYDTwZERcFxEr2lOemZlVrdWuobcBT5JuHXlfRLxCyRvSmJnZ2qPbIIiIXYGPAJsC10j6IzBE0pvaVZyZmVWv5cHiiLgvIk6JiB2ALwDnAbdKurkt1ZmZWeVKX046IuaQrkR6Aul2lWZmtg7o9X0FIiKA63tsaGZma4XSvyMwM7N1k4PAzKzmetw1JGl94J9JvyN4tX1EfK26sszMrF3KHCO4nHSRubnAi9WWY2Zm7VYmCEZGxITKKzEzs44oc4zgZkk7V16JmZl1RJktgr2AyZIeJu0aEuks0l0qrczMzNqiTBBMrLwKMzPrmG6DQNKm+V7Fz7SxHjMza7NWWwQXAB8knS0UpF1CXQLYtsK6zMysTboNgoj4YP6/TfvKMTOzdit1rSFJrwO2Bzbo6hcRvkuZmdk6oMwvi48BPg+MBO4A9gRuAd5TaWVmZtYWZX5H8HngHcCCiNgXeDuwpNKqzMysbcoEwQsR8QKk6w5FxH3ADmUmLmmCpPslzZd0Uot275D0iqQPlyvbzMz6S5ljBIskDQUuA34v6UlgcU8jSRoITAP2AxYBsyXNiIh7mrT7NnB170o3M7P+0GMQRMQh+eFpkv4AbAZcVWLa44D5EfEQgKQLgUnAPQ3tPgf8hrT7yczM2qzlriFJAyT9qas7Iq6PiBkR8VKJaY8AFha6F+V+xemPAA4BpvdQx7GS5kias2SJD0+YmfWnnm5evwK4U9KoPkxbTfpFQ/cZwIkR8UoPdZwVEWMjYuzw4cP7UIqZmXWn1SUmPhQRlwBbAPMk3Qo82zU8Ig7qYdqLgK0K3SNZ9djCWOBCSQDDgAMkLY+Iy0o/AzMzWy2tjhGcDFwCnN7Hac8Gtpe0DfAX4DDgiGKD4q+WJZ0LXOEQMDNrrzIHi6/vy4QjYrmkKaSzgQYC50TEPEnH5eEtjwuYmVl7tAqCHSXd1d3AMvcjiIiZwMyGfk0DICIm9zQ9MzPrf62C4GHgwHYVYmZmndEqCF6KiAVtq8TMzDqi1emjN7WtCjMz65hugyAiprSzEDMz64wyF50zM7N1mIPAzKzmSgeBpLGS1quyGDMza79SQSBpC+Bm4CPVlmNmZu1Wdovg48DPgGMqrMXMzDqgbBAcBfw7sJ6kN1dYj5mZtVmPQSBpX+C+iFgK/BT4ZOVVmZlZ25TZIvgk8JP8+CLgUEk+28jMbB3R0x3KhgJ7AlcCRMQ/gFnAAZVXZmZmbdHyMtQR8RSwXUO/o6osyMzM2qtXu3gkHVtVIWZm1hm93dd/XCVVmJlZx/Q2CJrdkN7MzNZivQ0C36jGzGwd09sg8H2GzczWMb0NghGVVGFmZh3T2yC4vZIqzMysY3obBGdWUoWZmXVMb4Pg7EqqMDOzjvHpo2ZmNdfbIDi9kirMzKxjehUEEXFZRXWYmVmH+HLSZmY15yAwM6s5B4GZWc05CMzMas5BYGZWcw4CM7OacxCYmdWcg8DMrOYcBGZmNVdpEEiaIOl+SfMlndRk+JGS7sp/N0vatcp6zMxsVZUFgaSBwDRgIjAGOFzSmIZmDwN7R8QuwNeBs6qqx8zMmqtyi2AcMD8iHoqIl4ALgUnFBhFxc0Q8mTtnASMrrMfMzJqoMghGAAsL3YtofavLTwJXNhsg6VhJcyTNWbJkST+WaGZmVQZBs3sXRNOG0r6kIDix2fCIOCsixkbE2OHDh/djiWZmNqjCaS8Ctip0jwQWNzaStAvpzmcTI+KJCusxM7MmqtwimA1sL2kbSesBhwEzig0kjQIuAY6KiAcqrMXMzLpR2RZBRCyXNAW4GhgInBMR8yQdl4dPB04BNgd+IAlgeUSMraomMzNbVZW7hoiImcDMhn7TC4+PAY6psgYzM2vNvyw2M6s5B4GZWc05CMzMas5BYGZWcw4CM7OacxCYmdWcg8DMrOYcBGZmNecgMDOrOQeBmVnNOQjMzGrOQWBmVnMOAjOzmnMQmJnVnIPAzKzmHARmZjXnIDAzqzkHgZlZzTkIzMxqzkFgZlZzDgIzs5pzEJiZ1ZyDwMys5hwEZmY15yAwM6s5B4GZWc05CMzMas5BYGZWcw4CM7OacxCYmdWcg8DMrOYcBGZmNecgMDOrOQeBmVnNOQjMzGrOQWBmVnOVBoGkCZLulzRf0klNhkvS9/LwuyTtXmU9Zma2qsqCQNJAYBowERgDHC5pTEOzicD2+e9Y4IdV1WNmZs1VuUUwDpgfEQ9FxEvAhcCkhjaTgPMimQUMlbRFhTWZmVmDQRVOewSwsNC9CBhfos0I4LFiI0nHkrYYAJZJur9/S+2zYcDS/pqYTlN/Tco6p9+WCS8P64Q16TNi6+4GVBkEzSqOPrQhIs4CzuqPovqTpDkRMbbTddiaw8uEFa0ty0OVu4YWAVsVukcCi/vQxszMKlRlEMwGtpe0jaT1gMOAGQ1tZgAfy2cP7Qk8HRGPNU7IzMyqU9muoYhYLmkKcDUwEDgnIuZJOi4Pnw7MBA4A5gPPAUdXVU9F1rjdVdZxXiasaK1YHhSxyi55MzOrEf+y2Mys5hwEZmY1V/sgkPRVSfPyJS7ukDRe0tlNfgXd1+kv64/pWPs1e+8k7SDpurys3CvpLEnvz913SFqWL6tyh6TzJO0jKSR9sjCNt+d+J7T3GVl/kfRGSRdIekjSXEm3SDokv99PS7pd0n2S/rMwzmmN77mkRyQNa/8zWFmVvyNY40l6J/BBYPeIeDG/IetFxDEdLs3WXN8DpkbE5QCSdo6Iu0knRSDpOuCEiJiTu/cB7gY+CvwkT+Mw4M62Vm39RpKAy4CfRcQRud/WwEHAk8AfI+KDkjYEbpd0aUTc1LGCS6j7FsEWwNKIeBEgIpZGxOL8jW8spG+Fkr6dU/8aSePy8IckHZTbTJZ0uaSr8rfBU5vNTNKXJM3OWx+nt+1ZWn/agvT7FwByCPTkUWCD/C1SwATgyorqs+q9B3gpn/kIQEQsiIjvFxtFxPPAHaSrJazR6h4EvwO2kvSApB9I2rtJm42B6yJiD+AZ4BvAfsAhwNcK7cYBRwK7AYd2BUkXSfuTLq43LrfZQ9I/9e/TsTaYClwr6UpJX5A0tOR4vwYOBd4F3Aa8WFF9Vr23kt7DliS9jrTO31B5Raup1kEQEcuAPUjXMVoCXCRpckOzl4Cr8uO7gesj4uX8eHSh3e8j4on8LeASYK+G6eyf/24nLUQ7khYSW4tExE+BnYBfAfsAsyStX2LUi0lBcDjwy8oKtLaTNE3SnZJm517vlnQX8DhwRUQ8nvt3d65+x8/hr3UQAETEKxFxXUScCkwB/rmhycvx2o8tVpC/yUXEClY+xtL4Zja7rtI3I2K3/LddRPwEW+tExOKIOCciJgHLgbeVGOdx4GXS1uT/rbhEq9Y84NV7p0TEZ4H3AsNzrz9GxC7AzsCnJe2W+z8BvK5hWkOAp6ostoxaB0E+A6T4rXw3YEEfJ7efpNfnA0QHA40Hh64GPiFpkzzvEZLe0Md5WYco3WxpcH78JmBz4C8lRz8FODEiXqmqPmuLa0nHfD5d6LdRY6OIeAD4JnBi7nUDcJCkIQCSPgTcuSYsD7U+awjYBPh+3s+7nHSpi2NJ+3N760bg58B2wAVdZ410iYjfSdoJuCUdL2QZ8C/A3/pcvVVtI0mLCt3fIV0Y8buSXsj9vlTY9G8pIm7u7wKt/SIiJB0MTJX0ZdJu5Wd57QO/aDpwgqRtIuIuSWcCN0oK0rq/Rpyh6EtM9IN8XGFsREzpdC1mZr1V611DZmbmLQIzs9rzFoGZWc05CMzMas5BYGZWcw4Csz6SdK6k57rOC8/9vpuvLFr6ipLNrkrZlzZmfeUgMCvI14fpjfnApDzuAGBfyv/AzGyN4CAwW9mcfJ359+Qrhfbkl6RLTEO69tBNpB8nAiDpi5L+lP+OL/T/ar5S7TXADoX+b85XsZ0r6Y+SdmycoaR/lXRPvorthX17mmavqfsvi80avQWYSLru1DRJPwfOjYjF3bR/EJiUtyQOB87P4yNpD+BoYDzpWlP/T9L1pC9ghwFvJ62DtwFz8/TOAo6LiAcljQd+QLrscdFJwDb5HhpDV/8pW905CMwK8nVfrgCukDScdK2YRyW9KyJu7Wa0S0gf7OOBTxX67wVcGhHPAki6BHg3KQgujYjncv8Z+f8mpMtU/6qwMdLsyqZ3Ab+QdBnpBilmq8W7hmydpnT7wK7bSI6V9NP8eKakrQrDjiuMs5mkY4EZpC2ET5I+fLtzIfB10qXIVxRn32KcZr/kHAA8VbhC7W4RsVOTdh8AppEuoT5Xkr/Q2WrxAmTrtIi4FLi00Ovohia7FTsknQ+8k3S/gY9FxIMl5vGopK8C1zQMugE4V9K3SKFwCHBUftzVfxBwIPCjiPiHpIclHRoRv8rHKHaJiFdva5kPSG8VEX+QdCNwBOniiU/1VKdZdxwEZiu7GJgcEct7bFkQET9q0u82SecCXbuUzo6I2wEkXUS6jeEC4I+F0Y4EfijpZGAwaWujeH/jgcD5kjYjBcrUiHiqN7WaNfK1hszMas7HCMzMas5BYGZWcw4CM7OacxCYmdWcg8DMrOYcBGZmNecgMDOruf8PTee7LvQrxjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Accuracy = [0.9079,0.9305, 0.9340]\n",
    "Methods = ['Simple', 'LSTM', 'GRU']\n",
    "Accuracy_pos = np.arange(len(Methods))\n",
    "plt.bar(Accuracy_pos, Accuracy, width=0.3, color=\"green\")\n",
    "plt.xticks(Accuracy_pos, Methods)\n",
    "plt.title('Comparing the Training accuracy of each model')\n",
    "plt.xlabel(\" ---> Models\")\n",
    "plt.ylabel(\" ---> Train Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397ffa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
